{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f5da2cf",
   "metadata": {},
   "source": [
    "### App 1\n",
    "The application allows users to enter a research topic, which triggers an agent to search arXiv, retrieve relevant papers, extract their content, convert them to embeddings, and store them in a vector database. Once indexing is complete, the system informs the user.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e1de25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !capture --no-stderr\n",
    "# !pip install --quiet -U langchain_openai langchain_core langchain langchain-community langchain_pinecone beautifulsoup4 requests pinecone tabulate\n",
    "# !pip install arxiv\n",
    "# !pip install PyPDF2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98a3e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv \n",
    "from langchain_openai import AzureOpenAIEmbeddings, AzureChatOpenAI \n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import langchain \n",
    "import arxiv \n",
    "import requests \n",
    "from PyPDF2 import PdfReader \n",
    "from io import BytesIO\n",
    "from tqdm import tqdm\n",
    "from pinecone import Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "891c8800",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "PINECONE_ENV = os.getenv(\"PINECONE_ENV\")\n",
    "PINECONE_INDEX_NAME = os.getenv(\"PINECONE_INDEX_NAME\", \"arxiv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5995f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Pinecone index: arxiv <pinecone.db_data.index.Index object at 0x000001ECEB820CE0>\n"
     ]
    }
   ],
   "source": [
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "index = pc.Index(\"arxiv\")\n",
    "print(\"Connected to Pinecone index:\", PINECONE_INDEX_NAME, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54685d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(\n",
    "    azure_deployment=\"gpt-4.1\",\n",
    "    temperature=0.2,\n",
    "    max_tokens=1000\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61a0a154",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "\n",
    "# Embeddings\n",
    "embeddings_model = AzureOpenAIEmbeddings(\n",
    "    azure_deployment=\"text-embedding-3-small\",\n",
    "    dimensions=1536\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c86cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_arxiv_papers(query, max_results=5):\n",
    "    search = arxiv.Search(\n",
    "        query=query,\n",
    "        max_results=max_results,\n",
    "        sort_by=arxiv.SortCriterion.Relevance\n",
    "    )\n",
    "    \n",
    "    client = arxiv.Client()\n",
    "\n",
    "    papers = []\n",
    "\n",
    "    for result in client.results(search):\n",
    "        try:\n",
    "            pdf_url = result.pdf_url\n",
    "            response = requests.get(pdf_url, timeout=20)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            pdf_file = BytesIO(response.content)\n",
    "            reader = PdfReader(pdf_file)\n",
    "            full_text = \"\"\n",
    "            for page in reader.pages:\n",
    "                page_text = page.extract_text()\n",
    "                if page_text:\n",
    "                    full_text += page_text + \"\\n\"\n",
    "\n",
    "            combined_text = (result.summary or \"\") + \"\\n\\n\" + full_text\n",
    "\n",
    "            papers.append({\n",
    "                \"id\": result.entry_id,\n",
    "                \"title\": result.title,\n",
    "                \"abstract\": result.summary,\n",
    "                \"url\": result.entry_id,\n",
    "                \"pdf_text\": full_text,\n",
    "                \"text\": combined_text[:2000],\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {result.title[:50]}... due to error: {e}\")\n",
    "\n",
    "    print(f\"Retrieved {len(papers)} papers for query '{query}'\")\n",
    "    return papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c63484aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Newer versions of LangChain\n",
    "    from langchain_core.documents import Document\n",
    "except ImportError:\n",
    "    # Older versions fallback\n",
    "    from langchain.docstore.document import Document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ded94f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_papers(papers, index, embeddings_model):\n",
    "    \"\"\"\n",
    "    Index papers into Pinecone, split into overlapping chunks for accurate retrieval.\n",
    "    \"\"\"\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200\n",
    "    )\n",
    "\n",
    "    vectors_to_upsert = []\n",
    "    total_chunks = 0\n",
    "\n",
    "    for paper in tqdm(papers, desc=\"Chunking and indexing papers\"):\n",
    "        text = paper.get(\"pdf_text\") or paper.get(\"content\")\n",
    "        if not text:\n",
    "            print(f\"Skipping '{paper.get('title', 'Unknown')}' — no text found.\")\n",
    "            continue\n",
    "\n",
    "        # Document object for LangChain splitter\n",
    "        docs = [Document(page_content=text, metadata=paper)]\n",
    "\n",
    "        # Split into smaller overlapping chunks\n",
    "        doc_chunks = splitter.split_documents(docs)\n",
    "\n",
    "        for i, chunk in enumerate(doc_chunks):\n",
    "            chunk_text = chunk.page_content.strip()\n",
    "            if not chunk_text:\n",
    "                continue\n",
    "\n",
    "            # Create embedding for each chunk\n",
    "            embedding = embeddings_model.embed_query(chunk_text)\n",
    "\n",
    "            # Add chunk metadata\n",
    "            metadata = {\n",
    "                \"title\": paper.get(\"title\", \"Unknown\"),\n",
    "                \"url\": paper.get(\"url\", \"\"),\n",
    "                \"chunk_id\": i,\n",
    "                \"text\": chunk_text,\n",
    "            }\n",
    "\n",
    "            # Unique ID per chunk (paper_id + chunk index)\n",
    "            paper_id = paper.get(\"id\") or paper.get(\"url\") or paper.get(\"title\", \"\")[:50]\n",
    "            chunk_id = f\"{paper_id}_chunk{i}\"\n",
    "\n",
    "            vectors_to_upsert.append((chunk_id, embedding, metadata))\n",
    "\n",
    "        total_chunks += len(doc_chunks)\n",
    "\n",
    "    # Upsert all chunks to Pinecone\n",
    "    if vectors_to_upsert:\n",
    "        index.upsert(vectors=vectors_to_upsert)\n",
    "        print(f\"Indexed {total_chunks} chunks from {len(papers)} papers.\")\n",
    "    else:\n",
    "        print(\"No chunks indexed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e0449d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37453bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Retrieved 5 papers for query 'deep learning'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunking and indexing papers: 100%|██████████| 5/5 [02:12<00:00, 26.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Indexed 344 chunks from 5 papers.\n",
      "✅ Indexed 5 papers on 'deep learning' in Pinecone!\n"
     ]
    }
   ],
   "source": [
    "topic = input(\"Enter research topic: \")\n",
    "papers = fetch_arxiv_papers(topic)\n",
    "index_papers(papers, index, embeddings_model)\n",
    "\n",
    "print(f\"Success: Indexed {len(papers)} papers on '{topic}' in Pinecone db!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89b995e",
   "metadata": {},
   "source": [
    "---------- end of app first --------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad953cf",
   "metadata": {},
   "source": [
    "## App 2\n",
    " application enables users to query the indexed knowledge base by entering research questions, which the agent retrieves relevant papers for using semantic search, generates informative responses grounded in those papers, and provides proper citations with links and metadata to the original sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a90c7918",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_pinecone import Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc8fed40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aneta\\AppData\\Local\\Temp\\ipykernel_6912\\4231391049.py:1: LangChainDeprecationWarning: The class `Pinecone` was deprecated in LangChain 0.0.3 and will be removed in 1.0.0. Use `PineconeVectorStore` instead.\n",
      "  vectorstore = Pinecone(\n"
     ]
    }
   ],
   "source": [
    "vectorstore = Pinecone(\n",
    "    index_name=os.environ[\"PINECONE_INDEX_NAME\"],\n",
    "    embedding=embeddings_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e265f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_context(query, k=5):\n",
    "    docs = vectorstore.similarity_search(query, k=k)\n",
    "    context_parts = []\n",
    "    sources = []\n",
    "\n",
    "    for d in docs:\n",
    "        # Fallback: use text from metadata if page_content is empty\n",
    "        content = d.page_content or d.metadata.get(\"text\", \"\")\n",
    "        if content:\n",
    "            context_parts.append(content)\n",
    "            sources.append(f\"- [{d.metadata.get('title', 'Untitled')}]({d.metadata.get('url', 'Unknown URL')})\")\n",
    "\n",
    "    context_text = \"\\n\\n\".join(context_parts)\n",
    "    return context_text, sources\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010ac827",
   "metadata": {},
   "outputs": [],
   "source": [
    "def research_qa(query, k=5):\n",
    "    context, sources = retrieve_context(query, k=k)\n",
    "\n",
    "    system_prompt = (\n",
    "        \"You are a helpful AI research assistant. \"\n",
    "        \"Use the provided academic paper excerpts to answer the user's question clearly and concisely. \"\n",
    "        \"Cite your sources at the end in markdown link format like [Title](URL). \"\n",
    "        \"If the answer cannot be found in the papers, say so explicitly.\"\n",
    "    )\n",
    "\n",
    "    user_prompt = f\"Question:\\n{query}\\n\\nContext:\\n{context}\"\n",
    "\n",
    "    messages = [\n",
    "        SystemMessage(content=system_prompt),\n",
    "        HumanMessage(content=user_prompt)\n",
    "    ]\n",
    "\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    print(\"\\nAnswer:\")\n",
    "    print(response.content)\n",
    "    print(\"\\nSources:\")\n",
    "    for s in sources:\n",
    "        print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ff626b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer:\n",
      "Deep learning algorithms are a subset of machine learning methods that use neural networks with many layers (hence \"deep\") to automatically learn hierarchical feature representations from raw data. The key characteristics and advantages of deep learning algorithms include:\n",
      "\n",
      "- **Layered Feature Representation:** Deep learning models learn successive layers of increasingly abstract and meaningful features from data. Each layer transforms the input data into a more complex representation, enabling the model to capture intricate patterns and relationships. This process is often referred to as \"feature representation learning\" ([A Review on Deep Learning Techniques Applied to Semantic Segmentation](https://arxiv.org/abs/1704.06857)).\n",
      "\n",
      "- **Automatic Feature Extraction:** Unlike traditional machine learning, which often requires manual feature engineering, deep learning algorithms automatically discover the features that best represent the data, making them highly effective for complex tasks ([Discriminative Unsupervised Feature Learning with Exemplar Convolutional Neural Networks](https://arxiv.org/abs/1406.6909)).\n",
      "\n",
      "- **Scalability and End-to-End Learning:** Deep learning architectures can scale to very large datasets and learn in an end-to-end fashion, meaning they can map raw inputs directly to desired outputs without the need for intermediate manual processing. This has enabled breakthroughs in fields such as image classification (e.g., ImageNet with AlexNet), speech recognition, machine translation, and robotics ([A Review on Deep Learning Techniques Applied to Semantic Segmentation](https://arxiv.org/abs/1704.06857)).\n",
      "\n",
      "- **Types of Architectures:** The main types of deep learning architectures include:\n",
      "  - Convolutional Neural Networks (CNNs) for image and spatial data\n",
      "  - Recurrent Neural Networks (RNNs) for sequential data like text and speech\n",
      "  - Recursive Neural Networks for hierarchical data\n",
      "  - Unsupervised pretrained networks for learning representations without labeled data\n",
      "\n",
      "- **Current Limitations:** While deep learning has achieved near-human accuracy in various tasks, current models often focus on \"surface learning\"—memorizing patterns in the data—rather than deeper, more abstract reasoning akin to human learning ([A Review on Deep Learning Techniques Applied to Semantic Segmentation](https://arxiv.org/abs/1704.06857)).\n",
      "\n",
      "In summary, deep learning algorithms are powerful tools for automatically learning complex representations from large datasets, driving advances in many AI application domains.\n",
      "\n",
      "**References:**\n",
      "- [A Review on Deep Learning Techniques Applied to Semantic Segmentation](https://arxiv.org/abs/1704.06857)\n",
      "- [Discriminative Unsupervised Feature Learning with Exemplar Convolutional Neural Networks](https://arxiv.org/abs/1406.6909)\n",
      "\n",
      "Sources:\n",
      "- [Opening the black box of deep learning](http://arxiv.org/abs/1805.08355v1)\n",
      "- [Concept-Oriented Deep Learning](http://arxiv.org/abs/1806.01756v1)\n",
      "- [Deep learning research landscape & roadmap in a nutshell: past, present and future -- Towards deep cortical learning](http://arxiv.org/abs/1908.02130v1)\n",
      "- [Concept-Oriented Deep Learning](http://arxiv.org/abs/1806.01756v1)\n",
      "- [Concept-Oriented Deep Learning](http://arxiv.org/abs/1806.01756v1)\n"
     ]
    }
   ],
   "source": [
    "question = input(\"Enter your research question: \")\n",
    "research_qa(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b885c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9730647e",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "<!-- https://colab.research.google.com/drive/1iA6VqdRi1RPirf3PtLfPT74UJiHdPKxr?usp=sharing#scrollTo=ApA0U6w5v8er -->\n",
    "<!-- https://colab.research.google.com/drive/1-o4mnBbFtTXfaP-2FaG3X3F6q5zxRUbW?usp=sharing#scrollTo=tD4t0206sPgC -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e81d960",
   "metadata": {},
   "source": [
    "to do:\n",
    "Part-2: Agentic Research Assistant\n",
    "\n",
    "Extend Part-1 by merging the two separate applications into a single unified system where an LLM-driven agent intelligently decides whether the user is in an indexing phase or a query phase based on user intent. The agent should manage state transitions explicitly—informing the user when indexing is complete and they can begin asking questions, or detecting when a user wants to start a new research topic. The system maintains conversational context and guides the user through natural transition points with clear communication about what can be done next, creating a seamless research workflow without requiring separate interfaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eba077b",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "!pip install langchain-text-splitters\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3ec70f",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fd5c76",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_pinecone import Pinecone\n",
    "\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Pinecone as PineconeVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac353b4d",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771f8b4e",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d523f09",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
